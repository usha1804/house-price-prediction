# -*- coding: utf-8 -*-
"""house price prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1giCG3RLivGp5vWoBcZU72WWCIvQO5_JV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler



data = pd.read_csv('housing.csv')

data.head()

data.shape

data.info()

data.isnull().sum()

data.dropna(inplace = True)

data.info()

data.info()

data.isnull().sum()

data.shape

X = data.drop(['median_house_value'], axis=1)
Y = data['median_house_value']

print(X)
print(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)

train_data = X_train.join(Y_train)
train_data

train_data.hist(figsize=(15,8))

train_data = train_data.join(pd.get_dummies(train_data.ocean_proximity)).drop(["ocean_proximity"],axis=1)

train_data['total_rooms'] = np.log(train_data['total_rooms'] + 1)
train_data['total_bedrooms'] = np.log(train_data['total_bedrooms'] + 1)
train_data['population'] = np.log(train_data['population'] + 1)
train_data['households'] = np.log(train_data['households'] + 1)

plt.figure(figsize=(15,8))
sns.heatmap(train_data.corr(), annot=True, cmap='YlGnBu')

train_data.hist(figsize=(15,10))
# They look noramal distribution (Gaussian bell)

plt.figure(figsize=(15,8))
sns.scatterplot(x='latitude', y='longitude', data=train_data, hue='median_house_value')

train_data['bedroom_ratio'] = train_data['total_bedrooms'] / train_data['total_rooms']
train_data['household_rooms'] = train_data['total_rooms'] / train_data['households']

plt.figure(figsize=(15,8))
sns.heatmap(train_data.corr(), annot=True, cmap='YlGnBu')

X_train , Y_train = train_data.drop(['median_house_value'], axis=1) , train_data['median_house_value']

reg = LinearRegression()
reg.fit(X_train,Y_train)

reg.score(X_train , Y_train)

test_data = X_test.join(Y_test)

test_data['total_rooms'] = np.log(test_data['total_rooms'] + 1)
test_data['total_bedrooms'] = np.log(test_data['total_bedrooms'] + 1)
test_data['population'] = np.log(test_data['population'] + 1)
test_data['households'] = np.log(test_data['households'] + 1)

test_data = test_data.join(pd.get_dummies(test_data.ocean_proximity)).drop(["ocean_proximity"],axis=1)
test_data['bedroom_ratio'] = test_data['total_bedrooms'] / test_data['total_rooms']
test_data['household_rooms'] = test_data['total_rooms'] / test_data['households']

test_data

X_test , Y_test = test_data.drop(['median_house_value'], axis=1) , test_data['median_house_value']

reg.score(X_test , Y_test)

scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
reg.fit(X_train_s , Y_train)

reg.score(X_train_s , Y_train)

X_test_s = scaler.transform(X_test)
reg.score(X_test_s , Y_test)